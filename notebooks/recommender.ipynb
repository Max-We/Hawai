{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install pandas\n",
        "!pip install --upgrade kagglehub\n",
        "!pip install -U LibRecommender\n",
        "!pip install keras==2.12.0 tensorflow==2.12.0\n",
        "\n",
        "!pip show LibRecommender"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "gS5ZkBCrWQOY",
        "outputId": "fc28711b-4c9c-4e8f-d40b-e93dc324a38c"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
            "Requirement already satisfied: numpy>=1.23.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Requirement already satisfied: kagglehub in /usr/local/lib/python3.11/dist-packages (0.3.10)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from kagglehub) (24.2)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from kagglehub) (6.0.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from kagglehub) (2.32.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from kagglehub) (4.67.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->kagglehub) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->kagglehub) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->kagglehub) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->kagglehub) (2025.1.31)\n",
            "Collecting LibRecommender\n",
            "  Downloading LibRecommender-1.5.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (30 kB)\n",
            "Collecting gensim>=4.0.0 (from LibRecommender)\n",
            "  Downloading gensim-4.3.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (8.1 kB)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from LibRecommender) (4.67.1)\n",
            "Collecting numpy<2.0,>=1.18.5 (from gensim>=4.0.0->LibRecommender)\n",
            "  Downloading numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.0/61.0 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting scipy<1.14.0,>=1.7.0 (from gensim>=4.0.0->LibRecommender)\n",
            "  Downloading scipy-1.13.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (60 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.6/60.6 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.11/dist-packages (from gensim>=4.0.0->LibRecommender) (7.1.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.11/dist-packages (from smart-open>=1.8.1->gensim>=4.0.0->LibRecommender) (1.17.2)\n",
            "Downloading LibRecommender-1.5.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m37.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading gensim-4.3.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (26.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m26.7/26.7 MB\u001b[0m \u001b[31m26.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.3/18.3 MB\u001b[0m \u001b[31m28.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading scipy-1.13.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (38.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m38.6/38.6 MB\u001b[0m \u001b[31m9.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: numpy, scipy, gensim, LibRecommender\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 2.0.2\n",
            "    Uninstalling numpy-2.0.2:\n",
            "      Successfully uninstalled numpy-2.0.2\n",
            "  Attempting uninstall: scipy\n",
            "    Found existing installation: scipy 1.14.1\n",
            "    Uninstalling scipy-1.14.1:\n",
            "      Successfully uninstalled scipy-1.14.1\n",
            "Successfully installed LibRecommender-1.5.1 gensim-4.3.3 numpy-1.26.4 scipy-1.13.1\n",
            "Collecting keras==2.12.0\n",
            "  Downloading keras-2.12.0-py2.py3-none-any.whl.metadata (1.4 kB)\n",
            "Collecting tensorflow==2.12.0\n",
            "  Downloading tensorflow-2.12.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.4 kB)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.12.0) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.12.0) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=2.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.12.0) (25.2.10)\n",
            "Collecting gast<=0.4.0,>=0.2.1 (from tensorflow==2.12.0)\n",
            "  Downloading gast-0.4.0-py3-none-any.whl.metadata (1.1 kB)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.12.0) (0.2.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.12.0) (1.71.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.12.0) (3.13.0)\n",
            "Requirement already satisfied: jax>=0.3.15 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.12.0) (0.5.2)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.12.0) (18.1.1)\n",
            "Collecting numpy<1.24,>=1.22 (from tensorflow==2.12.0)\n",
            "  Downloading numpy-1.23.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.3 kB)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.12.0) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.12.0) (24.2)\n",
            "Collecting protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 (from tensorflow==2.12.0)\n",
            "  Downloading protobuf-4.25.6-cp37-abi3-manylinux2014_x86_64.whl.metadata (541 bytes)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.12.0) (75.1.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.12.0) (1.17.0)\n",
            "Collecting tensorboard<2.13,>=2.12 (from tensorflow==2.12.0)\n",
            "  Downloading tensorboard-2.12.3-py3-none-any.whl.metadata (1.8 kB)\n",
            "Collecting tensorflow-estimator<2.13,>=2.12.0 (from tensorflow==2.12.0)\n",
            "  Downloading tensorflow_estimator-2.12.0-py2.py3-none-any.whl.metadata (1.3 kB)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.12.0) (2.5.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.12.0) (4.12.2)\n",
            "Collecting wrapt<1.15,>=1.11.0 (from tensorflow==2.12.0)\n",
            "  Downloading wrapt-1.14.1-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.12.0) (0.37.1)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from astunparse>=1.6.0->tensorflow==2.12.0) (0.45.1)\n",
            "Requirement already satisfied: jaxlib<=0.5.2,>=0.5.1 in /usr/local/lib/python3.11/dist-packages (from jax>=0.3.15->tensorflow==2.12.0) (0.5.1)\n",
            "Requirement already satisfied: ml_dtypes>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from jax>=0.3.15->tensorflow==2.12.0) (0.4.1)\n",
            "INFO: pip is looking at multiple versions of jax to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting jax>=0.3.15 (from tensorflow==2.12.0)\n",
            "  Downloading jax-0.5.3-py3-none-any.whl.metadata (22 kB)\n",
            "Collecting jaxlib<=0.5.3,>=0.5.3 (from jax>=0.3.15->tensorflow==2.12.0)\n",
            "  Downloading jaxlib-0.5.3-cp311-cp311-manylinux2014_x86_64.whl.metadata (1.2 kB)\n",
            "Collecting jax>=0.3.15 (from tensorflow==2.12.0)\n",
            "  Downloading jax-0.5.1-py3-none-any.whl.metadata (22 kB)\n",
            "  Downloading jax-0.5.0-py3-none-any.whl.metadata (22 kB)\n",
            "Collecting jaxlib<=0.5.0,>=0.5.0 (from jax>=0.3.15->tensorflow==2.12.0)\n",
            "  Downloading jaxlib-0.5.0-cp311-cp311-manylinux2014_x86_64.whl.metadata (978 bytes)\n",
            "Collecting jax>=0.3.15 (from tensorflow==2.12.0)\n",
            "  Downloading jax-0.4.38-py3-none-any.whl.metadata (22 kB)\n",
            "Collecting jaxlib<=0.4.38,>=0.4.38 (from jax>=0.3.15->tensorflow==2.12.0)\n",
            "  Downloading jaxlib-0.4.38-cp311-cp311-manylinux2014_x86_64.whl.metadata (1.0 kB)\n",
            "Collecting jax>=0.3.15 (from tensorflow==2.12.0)\n",
            "  Downloading jax-0.4.37-py3-none-any.whl.metadata (22 kB)\n",
            "Collecting jaxlib<=0.4.37,>=0.4.36 (from jax>=0.3.15->tensorflow==2.12.0)\n",
            "  Downloading jaxlib-0.4.36-cp311-cp311-manylinux2014_x86_64.whl.metadata (1.0 kB)\n",
            "Collecting jax>=0.3.15 (from tensorflow==2.12.0)\n",
            "  Downloading jax-0.4.36-py3-none-any.whl.metadata (22 kB)\n",
            "  Downloading jax-0.4.35-py3-none-any.whl.metadata (22 kB)\n",
            "Collecting jaxlib<=0.4.35,>=0.4.34 (from jax>=0.3.15->tensorflow==2.12.0)\n",
            "  Downloading jaxlib-0.4.35-cp311-cp311-manylinux2014_x86_64.whl.metadata (983 bytes)\n",
            "INFO: pip is still looking at multiple versions of jax to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting jax>=0.3.15 (from tensorflow==2.12.0)\n",
            "  Downloading jax-0.4.34-py3-none-any.whl.metadata (22 kB)\n",
            "Collecting jaxlib<=0.4.34,>=0.4.34 (from jax>=0.3.15->tensorflow==2.12.0)\n",
            "  Downloading jaxlib-0.4.34-cp311-cp311-manylinux2014_x86_64.whl.metadata (983 bytes)\n",
            "Collecting jax>=0.3.15 (from tensorflow==2.12.0)\n",
            "  Downloading jax-0.4.33-py3-none-any.whl.metadata (22 kB)\n",
            "Collecting jaxlib<=0.4.33,>=0.4.33 (from jax>=0.3.15->tensorflow==2.12.0)\n",
            "  Downloading jaxlib-0.4.33-cp311-cp311-manylinux2014_x86_64.whl.metadata (983 bytes)\n",
            "Collecting jax>=0.3.15 (from tensorflow==2.12.0)\n",
            "  Downloading jax-0.4.31-py3-none-any.whl.metadata (22 kB)\n",
            "Collecting jaxlib<=0.4.31,>=0.4.30 (from jax>=0.3.15->tensorflow==2.12.0)\n",
            "  Downloading jaxlib-0.4.31-cp311-cp311-manylinux2014_x86_64.whl.metadata (983 bytes)\n",
            "Collecting jax>=0.3.15 (from tensorflow==2.12.0)\n",
            "  Downloading jax-0.4.30-py3-none-any.whl.metadata (22 kB)\n",
            "Collecting jaxlib<=0.4.30,>=0.4.27 (from jax>=0.3.15->tensorflow==2.12.0)\n",
            "  Downloading jaxlib-0.4.30-cp311-cp311-manylinux2014_x86_64.whl.metadata (1.0 kB)\n",
            "Requirement already satisfied: scipy>=1.9 in /usr/local/lib/python3.11/dist-packages (from jax>=0.3.15->tensorflow==2.12.0) (1.13.1)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.13,>=2.12->tensorflow==2.12.0) (2.38.0)\n",
            "Collecting google-auth-oauthlib<1.1,>=0.5 (from tensorboard<2.13,>=2.12->tensorflow==2.12.0)\n",
            "  Downloading google_auth_oauthlib-1.0.0-py2.py3-none-any.whl.metadata (2.7 kB)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.13,>=2.12->tensorflow==2.12.0) (3.7)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.13,>=2.12->tensorflow==2.12.0) (2.32.3)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.13,>=2.12->tensorflow==2.12.0) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.13,>=2.12->tensorflow==2.12.0) (3.1.3)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow==2.12.0) (5.5.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow==2.12.0) (0.4.1)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.11/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow==2.12.0) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.13,>=2.12->tensorflow==2.12.0) (2.0.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow==2.12.0) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow==2.12.0) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow==2.12.0) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow==2.12.0) (2025.1.31)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from werkzeug>=1.0.1->tensorboard<2.13,>=2.12->tensorflow==2.12.0) (3.0.2)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.11/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow==2.12.0) (0.6.1)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.11/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.13,>=2.12->tensorflow==2.12.0) (3.2.2)\n",
            "Downloading keras-2.12.0-py2.py3-none-any.whl (1.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m64.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tensorflow-2.12.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (586.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m586.0/586.0 MB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading gast-0.4.0-py3-none-any.whl (9.8 kB)\n",
            "Downloading jax-0.4.30-py3-none-any.whl (2.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m50.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading numpy-1.23.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.1/17.1 MB\u001b[0m \u001b[31m87.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading protobuf-4.25.6-cp37-abi3-manylinux2014_x86_64.whl (294 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m294.6/294.6 kB\u001b[0m \u001b[31m22.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tensorboard-2.12.3-py3-none-any.whl (5.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.6/5.6 MB\u001b[0m \u001b[31m86.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tensorflow_estimator-2.12.0-py2.py3-none-any.whl (440 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m440.7/440.7 kB\u001b[0m \u001b[31m27.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading wrapt-1.14.1-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (78 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.4/78.4 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading google_auth_oauthlib-1.0.0-py2.py3-none-any.whl (18 kB)\n",
            "Downloading jaxlib-0.4.30-cp311-cp311-manylinux2014_x86_64.whl (79.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.6/79.6 MB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: wrapt, tensorflow-estimator, protobuf, numpy, keras, gast, jaxlib, google-auth-oauthlib, tensorboard, jax, tensorflow\n",
            "  Attempting uninstall: wrapt\n",
            "    Found existing installation: wrapt 1.17.2\n",
            "    Uninstalling wrapt-1.17.2:\n",
            "      Successfully uninstalled wrapt-1.17.2\n",
            "  Attempting uninstall: protobuf\n",
            "    Found existing installation: protobuf 5.29.3\n",
            "    Uninstalling protobuf-5.29.3:\n",
            "      Successfully uninstalled protobuf-5.29.3\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 1.26.4\n",
            "    Uninstalling numpy-1.26.4:\n",
            "      Successfully uninstalled numpy-1.26.4\n",
            "  Attempting uninstall: keras\n",
            "    Found existing installation: keras 3.8.0\n",
            "    Uninstalling keras-3.8.0:\n",
            "      Successfully uninstalled keras-3.8.0\n",
            "  Attempting uninstall: gast\n",
            "    Found existing installation: gast 0.6.0\n",
            "    Uninstalling gast-0.6.0:\n",
            "      Successfully uninstalled gast-0.6.0\n",
            "  Attempting uninstall: jaxlib\n",
            "    Found existing installation: jaxlib 0.5.1\n",
            "    Uninstalling jaxlib-0.5.1:\n",
            "      Successfully uninstalled jaxlib-0.5.1\n",
            "  Attempting uninstall: google-auth-oauthlib\n",
            "    Found existing installation: google-auth-oauthlib 1.2.1\n",
            "    Uninstalling google-auth-oauthlib-1.2.1:\n",
            "      Successfully uninstalled google-auth-oauthlib-1.2.1\n",
            "  Attempting uninstall: tensorboard\n",
            "    Found existing installation: tensorboard 2.18.0\n",
            "    Uninstalling tensorboard-2.18.0:\n",
            "      Successfully uninstalled tensorboard-2.18.0\n",
            "  Attempting uninstall: jax\n",
            "    Found existing installation: jax 0.5.2\n",
            "    Uninstalling jax-0.5.2:\n",
            "      Successfully uninstalled jax-0.5.2\n",
            "  Attempting uninstall: tensorflow\n",
            "    Found existing installation: tensorflow 2.18.0\n",
            "    Uninstalling tensorflow-2.18.0:\n",
            "      Successfully uninstalled tensorflow-2.18.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "albumentations 2.0.5 requires numpy>=1.24.4, but you have numpy 1.23.5 which is incompatible.\n",
            "xarray 2025.1.2 requires numpy>=1.24, but you have numpy 1.23.5 which is incompatible.\n",
            "treescope 0.1.9 requires numpy>=1.25.2, but you have numpy 1.23.5 which is incompatible.\n",
            "albucore 0.0.23 requires numpy>=1.24.4, but you have numpy 1.23.5 which is incompatible.\n",
            "tf-keras 2.18.0 requires tensorflow<2.19,>=2.18, but you have tensorflow 2.12.0 which is incompatible.\n",
            "bigframes 1.40.0 requires numpy>=1.24.0, but you have numpy 1.23.5 which is incompatible.\n",
            "blosc2 3.2.0 requires numpy>=1.26, but you have numpy 1.23.5 which is incompatible.\n",
            "chex 0.1.89 requires numpy>=1.24.1, but you have numpy 1.23.5 which is incompatible.\n",
            "grpcio-status 1.71.0 requires protobuf<6.0dev,>=5.26.1, but you have protobuf 4.25.6 which is incompatible.\n",
            "imbalanced-learn 0.13.0 requires numpy<3,>=1.24.3, but you have numpy 1.23.5 which is incompatible.\n",
            "orbax-checkpoint 0.11.9 requires jax>=0.5.0, but you have jax 0.4.30 which is incompatible.\n",
            "tensorflow-text 2.18.1 requires tensorflow<2.19,>=2.18.0, but you have tensorflow 2.12.0 which is incompatible.\n",
            "pymc 5.21.1 requires numpy>=1.25.0, but you have numpy 1.23.5 which is incompatible.\n",
            "scikit-image 0.25.2 requires numpy>=1.24, but you have numpy 1.23.5 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed gast-0.4.0 google-auth-oauthlib-1.0.0 jax-0.4.30 jaxlib-0.4.30 keras-2.12.0 numpy-1.23.5 protobuf-4.25.6 tensorboard-2.12.3 tensorflow-2.12.0 tensorflow-estimator-2.12.0 wrapt-1.14.1\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "numpy"
                ]
              },
              "id": "9db0ee597a56483daf0b251b393fbdf6"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name: LibRecommender\n",
            "Version: 1.5.1\n",
            "Summary: Versatile end-to-end recommender system.\n",
            "Home-page: https://github.com/massquantity/LibRecommender\n",
            "Author: massquantity\n",
            "Author-email: massquantity <jinxin_madie@163.com>\n",
            "License: MIT\n",
            "Location: /usr/local/lib/python3.11/dist-packages\n",
            "Requires: gensim, tqdm\n",
            "Required-by: \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 86,
      "metadata": {
        "id": "kDA15rXbWIoB"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "from libreco.data import random_split, DatasetPure\n",
        "from libreco.algorithms import BPR\n",
        "from libreco.evaluation import evaluate\n",
        "import kagglehub\n",
        "import tensorflow as tf\n",
        "\n",
        "class RecipeRecommender:\n",
        "    def __init__(self, data_path=\"shuyangli94/food-com-recipes-and-user-interactions\"):\n",
        "        # Initialize paths and parameters\n",
        "        self.data_path = data_path\n",
        "        self.model = None\n",
        "        self.data_info = None\n",
        "        self.name_df = None\n",
        "        self.data_filtered = None\n",
        "        self.train_data = None\n",
        "        self.eval_data = None\n",
        "        self.test_data = None\n",
        "        self.user_id_map = {}  # Maps UUIDs to numeric IDs\n",
        "\n",
        "        # Initialize recipe name mapping\n",
        "        self._load_recipe_names()\n",
        "\n",
        "    def _load_recipe_names(self):\n",
        "        \"\"\"Load recipe ID to name mapping\"\"\"\n",
        "        path = kagglehub.dataset_download(self.data_path)\n",
        "        raw_recipes_path = os.path.join(path, \"RAW_recipes.csv\")\n",
        "        self.name_df = pd.read_csv(raw_recipes_path)[[\"name\", \"id\"]]\n",
        "\n",
        "    def _rename_and_filter_data(self, interactions_data):\n",
        "      # Erzeuge explizite Kopie des DataFrames\n",
        "      df = interactions_data.copy()\n",
        "\n",
        "      # Spalten umbenennen (ohne inplace)\n",
        "      df = df.rename(columns={\n",
        "          \"user_id\": \"user\",\n",
        "          \"recipe_id\": \"item\",\n",
        "          \"rating\": \"label\"\n",
        "      })\n",
        "\n",
        "      # Spalten filtern\n",
        "      keep_cols = [\"user\", \"item\", \"label\"]\n",
        "      df = df[keep_cols]\n",
        "\n",
        "      # Typkonvertierung mit .loc\n",
        "      df.loc[:, \"label\"] = df[\"label\"].astype(int)\n",
        "      return df\n",
        "\n",
        "    def load_and_preprocess(self, min_interactions):\n",
        "        \"\"\"Load and preprocess interaction data\"\"\"\n",
        "        # Download and load dataset\n",
        "        path = kagglehub.dataset_download(self.data_path)\n",
        "\n",
        "        # Load and combine interaction data\n",
        "        train = pd.read_csv(os.path.join(path, \"interactions_train.csv\"))\n",
        "        eval = pd.read_csv(os.path.join(path, \"interactions_validation.csv\"))\n",
        "        test = pd.read_csv(os.path.join(path, \"interactions_test.csv\"))\n",
        "\n",
        "        combined = pd.concat([train, eval, test], ignore_index=True)\n",
        "        combined = self._rename_and_filter_data(combined)\n",
        "\n",
        "        # Filter items\n",
        "        item_counts = combined[\"item\"].value_counts()\n",
        "        items_to_keep = item_counts[item_counts >= min_interactions].index\n",
        "        filtered = combined[combined[\"item\"].isin(items_to_keep)]\n",
        "\n",
        "        # Filter users\n",
        "        user_counts = filtered[\"user\"].value_counts()\n",
        "        users_to_keep = user_counts[user_counts >= min_interactions].index\n",
        "        self.data_filtered = filtered[filtered[\"user\"].isin(users_to_keep)]\n",
        "\n",
        "    def train(self, embed_size=256, n_epochs=5, lr=5e-5):\n",
        "        \"\"\"Train the recommendation model\"\"\"\n",
        "        # Split data\n",
        "        self.train_data, self.eval_data, self.test_data = random_split(\n",
        "            self.data_filtered,\n",
        "            multi_ratios=[0.8, 0.1, 0.1]\n",
        "        )\n",
        "\n",
        "        # Build datasets\n",
        "        self.train_data, self.data_info = DatasetPure.build_trainset(self.train_data)\n",
        "        self.eval_data = DatasetPure.build_evalset(self.eval_data)\n",
        "        self.test_data = DatasetPure.build_testset(self.test_data)\n",
        "\n",
        "        # Initialize model\n",
        "        tf.compat.v1.reset_default_graph()\n",
        "        self.model = BPR(\n",
        "            task=\"ranking\",\n",
        "            data_info=self.data_info,\n",
        "            loss_type=\"bpr\",\n",
        "            embed_size=embed_size,\n",
        "            n_epochs=n_epochs,\n",
        "            lr=lr,\n",
        "            batch_size=1024,\n",
        "            num_neg=5,\n",
        "            reg=5e-6,\n",
        "            sampler=\"random\"\n",
        "        )\n",
        "\n",
        "        # Train model\n",
        "        self.model.fit(\n",
        "            self.train_data,\n",
        "            neg_sampling=True,\n",
        "            shuffle=True,\n",
        "            verbose=2,\n",
        "            eval_data=self.eval_data,\n",
        "            metrics=[\"loss\", \"roc_auc\", \"precision\", \"recall\", \"ndcg\"]\n",
        "        )\n",
        "\n",
        "    def evaluate(self):\n",
        "        \"\"\"Evaluate model performance\"\"\"\n",
        "        return evaluate(\n",
        "            model=self.model,\n",
        "            data=self.test_data,\n",
        "            neg_sampling=True,\n",
        "            metrics=[\"loss\", \"roc_auc\", \"precision\", \"recall\", \"ndcg\"]\n",
        "        )\n",
        "\n",
        "    def get_recommendation(self, user_identifier, n_rec=10):\n",
        "        \"\"\"Get recommendations for a user (UUID or numeric ID)\"\"\"\n",
        "        if not self.model:\n",
        "            raise ValueError(\"Model not trained. Call train() first.\")\n",
        "\n",
        "        # Handle UUID lookup\n",
        "        if isinstance(user_identifier, str):\n",
        "            if user_identifier not in self.user_id_map:\n",
        "                raise ValueError(f\"User UUID '{user_identifier}' not found.\")\n",
        "            user_id = self.user_id_map[user_identifier]\n",
        "        else:\n",
        "            user_id = user_identifier\n",
        "\n",
        "        recommendations = self.model.recommend_user(\n",
        "            user=user_id,\n",
        "            n_rec=n_rec,\n",
        "            filter_consumed=True\n",
        "        )\n",
        "\n",
        "        recipe_ids = recommendations[user_id]\n",
        "        return [self._get_recipe_name(rid) for rid in recipe_ids]\n",
        "\n",
        "    def get_recommendation_ids(self, user_identifier, n_rec=10):\n",
        "        \"\"\"Get recommendations for a user (UUID or numeric ID)\"\"\"\n",
        "        if not self.model:\n",
        "            raise ValueError(\"Model not trained. Call train() first.\")\n",
        "\n",
        "        # Handle UUID lookup\n",
        "        if isinstance(user_identifier, str):\n",
        "            if user_identifier not in self.user_id_map:\n",
        "                raise ValueError(f\"User UUID '{user_identifier}' not found.\")\n",
        "            user_id = self.user_id_map[user_identifier]\n",
        "        else:\n",
        "            user_id = user_identifier\n",
        "\n",
        "        recommendations = self.model.recommend_user(\n",
        "            user=user_id,\n",
        "            n_rec=n_rec,\n",
        "            filter_consumed=True\n",
        "        )\n",
        "\n",
        "        return recommendations[user_id]\n",
        "\n",
        "    def _get_recipe_name(self, recipe_id):\n",
        "        \"\"\"Helper to get recipe name from ID\"\"\"\n",
        "        name = self.name_df.loc[self.name_df['id'] == recipe_id, 'name']\n",
        "        return name.values[0] if not name.empty else \"Unknown Recipe\"\n",
        "\n",
        "    def import_ratings_csv(self, file_path):\n",
        "      \"\"\"Import ratings from CSV and map UUIDs to numeric IDs\"\"\"\n",
        "      try:\n",
        "          # Load CSV\n",
        "          df = pd.read_csv(file_path)\n",
        "          print(\"CSV erfolgreich geladen:\")\n",
        "          print(df.head())\n",
        "\n",
        "          # Check required columns\n",
        "          required = {\"uuid\", \"item_id\", \"rating\"}\n",
        "          if not required.issubset(df.columns):\n",
        "              missing = required - set(df.columns)\n",
        "              raise ValueError(f\"Fehlende Spalten: {missing}\")\n",
        "\n",
        "          # Process and map UUIDs\n",
        "          processed_df = self.__process_ratings(df)\n",
        "\n",
        "          # Add to data\n",
        "          self.data_filtered = pd.concat(\n",
        "              [self.data_filtered, processed_df],\n",
        "              ignore_index=True\n",
        "         )\n",
        "          print(f\"{len(processed_df)} neue Bewertungen hinzugefügt.\")\n",
        "\n",
        "      except FileNotFoundError:\n",
        "          print(f\"Datei {file_path} nicht gefunden.\")\n",
        "      except Exception as e:\n",
        "          print(f\"Fehler: {str(e)}\")\n",
        "\n",
        "    def __process_ratings(self, df):\n",
        "      \"\"\"Map UUIDs to numeric IDs\"\"\"\n",
        "      # Rename columns\n",
        "      df = df.rename(columns={\n",
        "          \"uuid\": \"user\",\n",
        "          \"item_id\": \"item\",\n",
        "          \"rating\": \"label\"\n",
        "      })\n",
        "\n",
        "      # Determine current max ID from user_id_map\n",
        "      current_max = max(self.user_id_map.values()) if self.user_id_map else 0\n",
        "\n",
        "      # Generate new IDs for unknown UUIDs\n",
        "      new_users = [uuid for uuid in df[\"user\"].unique() if uuid not in self.user_id_map]\n",
        "      num_new = len(new_users)\n",
        "\n",
        "      if num_new > 0:\n",
        "          new_ids = range(current_max + 1, current_max + num_new + 1)\n",
        "          self.user_id_map.update(zip(new_users, new_ids))\n",
        "\n",
        "      # Replace UUIDs with numeric IDs\n",
        "      df[\"user\"] = df[\"user\"].map(self.user_id_map)\n",
        "      return df\n",
        "\n",
        "\n",
        "    def info(self, UUID):\n",
        "      \"\"\"Gibt einen DataFrame mit allen Interaktionen des angegebenen Benutzers (UUID) zurück.\"\"\"\n",
        "      # Überprüfen, ob Daten geladen wurden\n",
        "      if self.data_filtered is None or not isinstance(self.data_filtered, pd.DataFrame):\n",
        "          return pd.DataFrame(columns=[\"user\", \"item\", \"label\", \"name\"])\n",
        "\n",
        "      # Prüfen, ob die UUID vorhanden ist\n",
        "      if UUID not in self.user_id_map:\n",
        "          return pd.DataFrame(columns=[\"user\", \"item\", \"label\", \"name\"])\n",
        "\n",
        "      # Numerische Benutzer-ID abrufen\n",
        "      user_id = self.user_id_map[UUID]\n",
        "\n",
        "      # Interaktionen filtern\n",
        "      user_interactions = self.data_filtered[self.data_filtered['user'] == user_id].copy()\n",
        "\n",
        "      if user_interactions.empty:\n",
        "          return pd.DataFrame(columns=[\"user\", \"item\", \"label\", \"name\"])\n",
        "\n",
        "      # UUID statt numerischer ID setzen\n",
        "      user_interactions['user'] = UUID\n",
        "\n",
        "      # Rezeptnamen hinzufügen\n",
        "      merged = user_interactions.merge(self.name_df, left_on='item', right_on='id', how='left')\n",
        "      merged['name'] = merged['name'].fillna('Unknown Recipe')\n",
        "\n",
        "      # Ergebnis formatieren\n",
        "      result = merged[['user', 'item', 'label', 'name']]\n",
        "\n",
        "      return result"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Beispielaufruf\n",
        "recommender = RecipeRecommender()\n",
        "recommender.load_and_preprocess(min_interactions=20)\n",
        "# Neue Nutzer per CSV importieren\n",
        "recommender.import_ratings_csv(\"/content/sample_data/ratings.csv\")\n",
        "recommender.train()\n",
        "recommender.evaluate()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ou5fJq46b9og",
        "outputId": "83fc6ea6-88e0-4c89-e161-30bf997d34b3"
      },
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CSV erfolgreich geladen:\n",
            "                                   uuid  item_id  rating\n",
            "0  df903ba4-a8f3-406f-814d-4420b00ab611    58086     2.0\n",
            "1  df903ba4-a8f3-406f-814d-4420b00ab611    40621     1.0\n",
            "2  df903ba4-a8f3-406f-814d-4420b00ab611    85475     0.0\n",
            "3  df903ba4-a8f3-406f-814d-4420b00ab611    71967     0.0\n",
            "4  df903ba4-a8f3-406f-814d-4420b00ab611    38584     1.0\n",
            "75 neue Bewertungen hinzugefügt.\n",
            "Training start time: \u001b[35m2025-03-23 22:19:14\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "train: 100%|██████████| 517/517 [00:06<00:00, 74.62it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1 elapsed: 6.932s\n",
            "\t \u001b[32mtrain_loss: 0.6923\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "eval_pointwise: 100%|██████████| 10/10 [00:00<00:00, 139.84it/s]\n",
            "eval_listwise: 100%|██████████| 2362/2362 [00:01<00:00, 1429.59it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\t eval log_loss: 0.6926\n",
            "\t eval roc_auc: 0.5466\n",
            "\t eval precision@10: 0.0037\n",
            "\t eval recall@10: 0.0069\n",
            "\t eval ndcg@10: 0.0176\n",
            "==============================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "train: 100%|██████████| 517/517 [00:06<00:00, 86.09it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2 elapsed: 6.015s\n",
            "\t \u001b[32mtrain_loss: 0.6905\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "eval_pointwise: 100%|██████████| 10/10 [00:00<00:00, 164.06it/s]\n",
            "eval_listwise: 100%|██████████| 2362/2362 [00:02<00:00, 972.75it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\t eval log_loss: 0.6920\n",
            "\t eval roc_auc: 0.5776\n",
            "\t eval precision@10: 0.0089\n",
            "\t eval recall@10: 0.0176\n",
            "\t eval ndcg@10: 0.0404\n",
            "==============================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "train: 100%|██████████| 517/517 [00:06<00:00, 79.52it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3 elapsed: 6.508s\n",
            "\t \u001b[32mtrain_loss: 0.6885\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "eval_pointwise: 100%|██████████| 10/10 [00:00<00:00, 159.53it/s]\n",
            "eval_listwise: 100%|██████████| 2362/2362 [00:01<00:00, 1376.72it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\t eval log_loss: 0.6915\n",
            "\t eval roc_auc: 0.6011\n",
            "\t eval precision@10: 0.0120\n",
            "\t eval recall@10: 0.0236\n",
            "\t eval ndcg@10: 0.0518\n",
            "==============================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "train: 100%|██████████| 517/517 [00:06<00:00, 75.59it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4 elapsed: 6.842s\n",
            "\t \u001b[32mtrain_loss: 0.6866\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "eval_pointwise: 100%|██████████| 10/10 [00:00<00:00, 141.03it/s]\n",
            "eval_listwise: 100%|██████████| 2362/2362 [00:01<00:00, 1431.55it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\t eval log_loss: 0.6909\n",
            "\t eval roc_auc: 0.6182\n",
            "\t eval precision@10: 0.0133\n",
            "\t eval recall@10: 0.0261\n",
            "\t eval ndcg@10: 0.0574\n",
            "==============================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "train: 100%|██████████| 517/517 [00:05<00:00, 86.62it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5 elapsed: 5.977s\n",
            "\t \u001b[32mtrain_loss: 0.6847\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "eval_pointwise: 100%|██████████| 10/10 [00:00<00:00, 165.19it/s]\n",
            "eval_listwise: 100%|██████████| 2362/2362 [00:02<00:00, 1056.40it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\t eval log_loss: 0.6904\n",
            "\t eval roc_auc: 0.6302\n",
            "\t eval precision@10: 0.0143\n",
            "\t eval recall@10: 0.0279\n",
            "\t eval ndcg@10: 0.0606\n",
            "==============================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "eval_pointwise: 100%|██████████| 10/10 [00:00<00:00, 106.60it/s]\n",
            "eval_listwise: 100%|██████████| 2389/2389 [00:02<00:00, 1039.94it/s]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'loss': 0.6903283554432341,\n",
              " 'roc_auc': 0.6360119191796274,\n",
              " 'precision': 0.01506906655504395,\n",
              " 'recall': 0.03275767970283889,\n",
              " 'ndcg': 0.06495866939135236}"
            ]
          },
          "metadata": {},
          "execution_count": 87
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "recommender.info(\"df903ba4-a8f3-406f-814d-4420b00ab611\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 520
        },
        "id": "ITc2b4S26zz_",
        "outputId": "42be5aca-3f16-4752-cca8-18bfda19cef1"
      },
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                    user   item  label  \\\n",
              "0   df903ba4-a8f3-406f-814d-4420b00ab611  58086    2.0   \n",
              "1   df903ba4-a8f3-406f-814d-4420b00ab611  40621    1.0   \n",
              "2   df903ba4-a8f3-406f-814d-4420b00ab611  85475    0.0   \n",
              "3   df903ba4-a8f3-406f-814d-4420b00ab611  71967    0.0   \n",
              "4   df903ba4-a8f3-406f-814d-4420b00ab611  38584    1.0   \n",
              "5   df903ba4-a8f3-406f-814d-4420b00ab611  50719    1.0   \n",
              "6   df903ba4-a8f3-406f-814d-4420b00ab611  17987    1.0   \n",
              "7   df903ba4-a8f3-406f-814d-4420b00ab611  78747    0.0   \n",
              "8   df903ba4-a8f3-406f-814d-4420b00ab611  26526    0.0   \n",
              "9   df903ba4-a8f3-406f-814d-4420b00ab611  16716    2.0   \n",
              "10  df903ba4-a8f3-406f-814d-4420b00ab611  95068    1.0   \n",
              "11  df903ba4-a8f3-406f-814d-4420b00ab611  95601    0.0   \n",
              "12  df903ba4-a8f3-406f-814d-4420b00ab611  97838    1.0   \n",
              "13  df903ba4-a8f3-406f-814d-4420b00ab611  44833    1.0   \n",
              "14  df903ba4-a8f3-406f-814d-4420b00ab611  56276    0.0   \n",
              "\n",
              "                                         name  \n",
              "0                                 dijon beets  \n",
              "1                  fish cakes fast and simple  \n",
              "2              dijon chicken with panko crust  \n",
              "3                         homemade mayonnaise  \n",
              "4      yummy and super easy crock pot oatmeal  \n",
              "5              the sweetest blueberry muffins  \n",
              "6                 quick butternut squash soup  \n",
              "7     gallo pinto  costa rican rice and beans  \n",
              "8                           amish white bread  \n",
              "9                          best ever buckeyes  \n",
              "10  just like loaded baked potatoes casserole  \n",
              "11                 hamburger steak with gravy  \n",
              "12             super easy honey curry chicken  \n",
              "13                          parmesan zucchini  \n",
              "14                       honey i m home bread  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-37050fea-2da0-4dec-a63a-e0b15a66af15\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>user</th>\n",
              "      <th>item</th>\n",
              "      <th>label</th>\n",
              "      <th>name</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>df903ba4-a8f3-406f-814d-4420b00ab611</td>\n",
              "      <td>58086</td>\n",
              "      <td>2.0</td>\n",
              "      <td>dijon beets</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>df903ba4-a8f3-406f-814d-4420b00ab611</td>\n",
              "      <td>40621</td>\n",
              "      <td>1.0</td>\n",
              "      <td>fish cakes fast and simple</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>df903ba4-a8f3-406f-814d-4420b00ab611</td>\n",
              "      <td>85475</td>\n",
              "      <td>0.0</td>\n",
              "      <td>dijon chicken with panko crust</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>df903ba4-a8f3-406f-814d-4420b00ab611</td>\n",
              "      <td>71967</td>\n",
              "      <td>0.0</td>\n",
              "      <td>homemade mayonnaise</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>df903ba4-a8f3-406f-814d-4420b00ab611</td>\n",
              "      <td>38584</td>\n",
              "      <td>1.0</td>\n",
              "      <td>yummy and super easy crock pot oatmeal</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>df903ba4-a8f3-406f-814d-4420b00ab611</td>\n",
              "      <td>50719</td>\n",
              "      <td>1.0</td>\n",
              "      <td>the sweetest blueberry muffins</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>df903ba4-a8f3-406f-814d-4420b00ab611</td>\n",
              "      <td>17987</td>\n",
              "      <td>1.0</td>\n",
              "      <td>quick butternut squash soup</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>df903ba4-a8f3-406f-814d-4420b00ab611</td>\n",
              "      <td>78747</td>\n",
              "      <td>0.0</td>\n",
              "      <td>gallo pinto  costa rican rice and beans</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>df903ba4-a8f3-406f-814d-4420b00ab611</td>\n",
              "      <td>26526</td>\n",
              "      <td>0.0</td>\n",
              "      <td>amish white bread</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>df903ba4-a8f3-406f-814d-4420b00ab611</td>\n",
              "      <td>16716</td>\n",
              "      <td>2.0</td>\n",
              "      <td>best ever buckeyes</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>df903ba4-a8f3-406f-814d-4420b00ab611</td>\n",
              "      <td>95068</td>\n",
              "      <td>1.0</td>\n",
              "      <td>just like loaded baked potatoes casserole</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>df903ba4-a8f3-406f-814d-4420b00ab611</td>\n",
              "      <td>95601</td>\n",
              "      <td>0.0</td>\n",
              "      <td>hamburger steak with gravy</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>df903ba4-a8f3-406f-814d-4420b00ab611</td>\n",
              "      <td>97838</td>\n",
              "      <td>1.0</td>\n",
              "      <td>super easy honey curry chicken</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>df903ba4-a8f3-406f-814d-4420b00ab611</td>\n",
              "      <td>44833</td>\n",
              "      <td>1.0</td>\n",
              "      <td>parmesan zucchini</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>df903ba4-a8f3-406f-814d-4420b00ab611</td>\n",
              "      <td>56276</td>\n",
              "      <td>0.0</td>\n",
              "      <td>honey i m home bread</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-37050fea-2da0-4dec-a63a-e0b15a66af15')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-37050fea-2da0-4dec-a63a-e0b15a66af15 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-37050fea-2da0-4dec-a63a-e0b15a66af15');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-98a02175-4db9-4761-b3be-17d3ba409f4c\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-98a02175-4db9-4761-b3be-17d3ba409f4c')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-98a02175-4db9-4761-b3be-17d3ba409f4c button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"recommender\",\n  \"rows\": 15,\n  \"fields\": [\n    {\n      \"column\": \"user\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"df903ba4-a8f3-406f-814d-4420b00ab611\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"item\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 27977,\n        \"min\": 16716,\n        \"max\": 97838,\n        \"num_unique_values\": 15,\n        \"samples\": [\n          16716\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"label\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.7037315505489968,\n        \"min\": 0.0,\n        \"max\": 2.0,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          2.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"name\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 15,\n        \"samples\": [\n          \"best ever buckeyes\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 88
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Empfehlungen für importierten Nutzer (UUID)\n",
        "print(recommender.get_recommendation(\"df903ba4-a8f3-406f-814d-4420b00ab611\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SRTFdV-BtIMu",
        "outputId": "c6f021e5-3d80-4610-98e5-de4a6246b879"
      },
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['crock pot chicken with black beans   cream cheese', 'japanese mum s chicken', 'creamy cajun chicken pasta', 'to die for crock pot roast', 'yes  virginia there is a great meatloaf', 'oven fried chicken chimichangas', 'kittencal s moist cheddar garlic oven fried chicken breast', 'creamy burrito casserole', 'greek potatoes  oven roasted and delicious', 'whatever floats your boat  brownies']\n"
          ]
        }
      ]
    }
  ]
}